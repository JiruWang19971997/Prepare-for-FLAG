# 任务目标
挑战：完成海量文本匹配任务 
- 数据量过亿，使用bert的nsp进行n x n匹配效果最好，但是不能实现一天内计算完成。
- 因此只能计算文本向量表示，最后统一进行矩阵计算和相似度排序。
- 

# 对比学习的理解
在普通多分类模型中，计算交叉熵的时候，出现了特殊情况：**即类别过多（例如每条文本是一个类别，有过多文本）**，则使用对比学习。     
具体操作是：多分类转为二分类，对一个样本分别使用正样本采样和负样本采样，让模型去判断，这个采样的样本，是正样本还是负样本。
- 小样本
- 正样本好构造

# 模型：
BERT句向量不能直接用于计算cos相似度
